{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Super Resolution - ESRGAN - TF.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsanzd/deep-learning-coursera/blob/master/Image_Super_Resolution_ESRGAN_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfr8LRz26Z-C"
      },
      "source": [
        "## Inference with ESRGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzXQlVKb6XbY"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "\r\n",
        "import os, glob\r\n",
        "import time\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeysHzAU8Gwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea8de14-1fb8-4a93-f422-fd2f63fe16bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCJgZLAS83Xk"
      },
      "source": [
        "# Define paths\r\n",
        "INPUT_DIR = '/content/drive/MyDrive/SpainAI'\r\n",
        "TRAIN_FOLDER  = 'TrainSet'\r\n",
        "TEST_FOLDER = 'TestSet'\r\n",
        "\r\n",
        "OUT_DIR = os.path.join(INPUT_DIR, TEST_FOLDER, 'Upscaled_ESRGAN_inference')\r\n",
        "\r\n",
        "if not os.path.exists(OUT_DIR):\r\n",
        "    os.makedirs(OUT_DIR)\r\n",
        "\r\n",
        "CWD = os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPa9qkeq9SwK",
        "outputId": "7d475463-78a7-4f70-f6b4-aa257b5c60ec"
      },
      "source": [
        "os.chdir(os.path.join(INPUT_DIR, TRAIN_FOLDER))\r\n",
        "train_imgs = glob.glob('*.png')\r\n",
        "os.chdir(CWD)\r\n",
        "\r\n",
        "os.chdir(os.path.join(INPUT_DIR, TEST_FOLDER))\r\n",
        "test_imgs = glob.glob('*.png')\r\n",
        "os.chdir(CWD)\r\n",
        "\r\n",
        "random.shuffle(train_imgs)\r\n",
        "num_val_imgs = int(0.2 * len(train_imgs))\r\n",
        "val_imgs = train_imgs[:num_val_imgs]\r\n",
        "train_imgs = train_imgs[num_val_imgs:]\r\n",
        "\r\n",
        "print('Len of the train files: ', len(train_imgs))\r\n",
        "print('Len of the val files: ', len(val_imgs))\r\n",
        "print('Len of the test files: ', len(test_imgs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Len of the files:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1oYK_ua-GzV"
      },
      "source": [
        "### Definition auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfGff5cf-Oh8"
      },
      "source": [
        "def preprocess_image(image_path):\r\n",
        "  \"\"\" Loads image from path and preprocesses to make it model ready\r\n",
        "      Args:\r\n",
        "        image_path: Path to the image file\r\n",
        "  \"\"\"\r\n",
        "  hr_image = tf.image.decode_image(tf.io.read_file(image_path))\r\n",
        "  # If PNG, remove the alpha channel. The model only supports\r\n",
        "  # images with 3 color channels.\r\n",
        "  if hr_image.shape[-1] == 4:\r\n",
        "    hr_image = hr_image[...,:-1]\r\n",
        "  hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 4) * 4\r\n",
        "  hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\r\n",
        "  hr_image = tf.cast(hr_image, tf.float32)\r\n",
        "  return tf.expand_dims(hr_image, 0)\r\n",
        "\r\n",
        "def save_image(image, filepath):\r\n",
        "  \"\"\"\r\n",
        "    Saves unscaled Tensor Images.\r\n",
        "    Args:\r\n",
        "      image: 3D image tensor. [height, width, channels]\r\n",
        "      filepath: Name of the file to save to.\r\n",
        "  \"\"\"\r\n",
        "  if not isinstance(image, Image.Image):\r\n",
        "    image = tf.clip_by_value(image, 0, 255)\r\n",
        "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\r\n",
        "  \r\n",
        "  image.save(filepath)\r\n",
        "  print(\"Saved as \", filepath)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PQE7VUw-pPW"
      },
      "source": [
        "%matplotlib inline\r\n",
        "def plot_image(image, title=\"\"):\r\n",
        "  \"\"\"\r\n",
        "    Plots images from image tensors.\r\n",
        "    Args:\r\n",
        "      image: 3D image tensor. [height, width, channels].\r\n",
        "      title: Title to display in the plot.\r\n",
        "  \"\"\"\r\n",
        "  image = np.asarray(image)\r\n",
        "  image = tf.clip_by_value(image, 0, 255)\r\n",
        "  image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\r\n",
        "  plt.imshow(image)\r\n",
        "  plt.axis(\"off\")\r\n",
        "  plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqhqb77i-RXb"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmR0ZI1N6jik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55de58ed-96b1-4ec5-e368-0d89887f6575"
      },
      "source": [
        "model = hub.load(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded https://tfhub.dev/captain-pool/esrgan-tf2/1, Total size: 20.60MB\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEBx7BpGRQC9"
      },
      "source": [
        "## Inference on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCjW2r09lR7k"
      },
      "source": [
        "# Calculating PSNR wrt Original Image\r\n",
        "def calculate_ssim(gen_image, hr_image, printed=True):\r\n",
        "    ssim = tf.image.ssim(tf.clip_by_value(gen_image, 0, 255),\r\n",
        "                  tf.clip_by_value(hr_image, 0, 255),\r\n",
        "                  max_val=255)\r\n",
        "    if printed:\r\n",
        "        print(\"SSIM Achieved: %f\" % ssim)\r\n",
        "        \r\n",
        "    return ssim\r\n",
        "\r\n",
        "def calculate_psnr(gen_image, hr_image):\r\n",
        "    psnr = tf.image.psnr(\r\n",
        "        tf.clip_by_value(gen_image, 0, 255),\r\n",
        "        tf.clip_by_value(hr_image, 0, 255), max_val=255)\r\n",
        "    print(\"PSNR Achieved: %f\" % psnr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfWw1Te7ALep"
      },
      "source": [
        "for filename in img_list:\r\n",
        "    img_path = os.path.join(INPUT_DIR, TEST_FOLDER, filename)\r\n",
        "    dest_name = 'candidate_' + filename.split('_',2)[-1]\r\n",
        "    dest_path = os.path.join(OUT_DIR, dest_name)\r\n",
        "    lr_image = preprocess_image(img_path)\r\n",
        "    sr_image = model(lr_image)\r\n",
        "    # plot_image(tf.squeeze(sr_image), title=\"Generated image\")\r\n",
        "    save_image(tf.squeeze(sr_image), filepath=dest_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JFllUUZRcWp"
      },
      "source": [
        "## Fine tuning of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv4jWAG4mb2l"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XySnpVDTRfGI"
      },
      "source": [
        "generator = tf.keras.models.Sequential([\r\n",
        "    hub.KerasLayer(\"https://tfhub.dev/captain-pool/esrgan-tf2/1\", trainable=True, input_shape=(256,256, 3)),\r\n",
        "    tf.keras.layers.Conv2D(filters=3, kernel_size=[1, 1], strides=[1, 1])\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHKo48dxpijl",
        "outputId": "0b3ba14e-2900-41de-8d7f-7913112e9d2d"
      },
      "source": [
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_5 (KerasLayer)   (None, None, None, 3)     4605955   \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, None, None, 3)     12        \n",
            "=================================================================\n",
            "Total params: 4,605,967\n",
            "Trainable params: 4,605,967\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceC_y0rTq3xu",
        "outputId": "e2911087-70e1-4dab-fd84-55529e6ff6d4"
      },
      "source": [
        "len(generator.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6GfSQMe2Eem"
      },
      "source": [
        "EPOCHS = 100\r\n",
        "LR = 5e-5\r\n",
        "BS = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TZ8t3gsz_0a"
      },
      "source": [
        "### Preparing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvbP8PN0CUW"
      },
      "source": [
        "# preprocessing function\r\n",
        "def map_image(lr_image_path, hr_image_path):\r\n",
        "    lr_image = preprocess_image(lr_image_path)\r\n",
        "    lr_image = tf.clip_by_value(tf.squeeze(lr_image), 0, 255)\r\n",
        "    lr_image = Image.fromarray(tf.cast(lr_image, tf.uint8).numpy())\r\n",
        "\r\n",
        "    hr_image = tf.image.decode_image(tf.io.read_file(hr_image_path))\r\n",
        "    hr_image = np.asarray(hr_image)\r\n",
        "    hr_image = tf.clip_by_value(tf.squeeze(lr_image), 0, 255)\r\n",
        "    hr_image = Image.fromarray(tf.cast(hr_image, tf.uint8).numpy())\r\n",
        "\r\n",
        "    return lr_image, hr_image\r\n",
        "\r\n",
        "\r\n",
        "# Prepare the training dataset.\r\n",
        "batch_size = BS\r\n",
        "\r\n",
        "# Prepare the training dataset. preprocess the dataset with the `map_image()` function above\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_imgs, train_imgs_hr)).map(map_image)\r\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\r\n",
        "\r\n",
        "# Prepare the validation dataset. preprocess the dataset with the `map_image()` function above\r\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_imgs, val_imgs_hr)).map(map_image)\r\n",
        "val_dataset = val_dataset.batch(batch_size)\r\n",
        "\r\n",
        "# Alternative. Using ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dazqqesz8-Dn"
      },
      "source": [
        "### Define losses and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxBUemzy9DAr"
      },
      "source": [
        "def ssim_loss(gen, target):\r\n",
        "    ssim_loss = 1 - tf.reduce_mean(calculate_ssim(gen, target, printed=False))\r\n",
        "    return ssim_loss\r\n",
        "\r\n",
        "def ssim_metric(gen, target):\r\n",
        "    return tf.reduce_mean(calculate_ssim(gen, target, printed=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LCzoC3piJU4"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlzGX6HkiNWA"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "hDO0ip73qBl1",
        "outputId": "d240aa38-c4e1-42fb-b92b-94c65e77cb9b"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\r\n",
        "    start_time = time.time()\r\n",
        "\r\n",
        "    train_ssim_batch_acc = []\r\n",
        "    val_ssim_batch_acc = []\r\n",
        "\r\n",
        "    # Iterate over the batches of the dataset.\r\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\r\n",
        "\r\n",
        "        # Open a GradientTape to record the operations run\r\n",
        "        # during the forward pass, which enables auto-differentiation.\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "            # Run the forward pass of the layer.\r\n",
        "            # The operations that the layer applies\r\n",
        "            # to its inputs are going to be recorded\r\n",
        "            # on the GradientTape.\r\n",
        "            gen_batch_train = generator(x_batch_train)  \r\n",
        "\r\n",
        "            # Compute the loss value for this minibatch.\r\n",
        "            loss_value = ssim_loss(gen_batch_train, y_batch_train)\r\n",
        "\r\n",
        "        # Use the gradient tape to automatically retrieve\r\n",
        "        # the gradients of the trainable variables with respect to the loss.\r\n",
        "        grads = tape.gradient(loss_value, generator.trainable_weights)\r\n",
        "\r\n",
        "        # Run one step of gradient descent by updating\r\n",
        "        # the value of the variables to minimize the loss.\r\n",
        "        optimizer.apply_gradients(zip(grads, generator.trainable_weights))\r\n",
        "\r\n",
        "        # Update training metric.\r\n",
        "        train_ssim_batch_acc.append(ssim_metric(gen_batch_train, y_batch_train))\r\n",
        "\r\n",
        "        # Log every 200 batches.\r\n",
        "        if step % 200 == 0:\r\n",
        "            print(\r\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\r\n",
        "                % (step, float(loss_value))\r\n",
        "            )\r\n",
        "            print(\"Seen so far: %s samples\" % ((step + 1) * 64))\r\n",
        "\r\n",
        "    # Display metrics at the end of each epoch.\r\n",
        "    train_ssim = tf.reduce_mean(train_ssim_batch_acc)\r\n",
        "    print(\"Training ssim over epoch: %.4f\" % (float(train_ssim),))\r\n",
        "\r\n",
        "    # Run a validation loop at the end of each epoch.\r\n",
        "    for x_batch_val, y_batch_val in val_dataset:\r\n",
        "        gen_batch_val = generator(x_batch_val)\r\n",
        "\r\n",
        "        # Update val metrics\r\n",
        "        val_ssim_batch_acc.append(ssim_metric(gen_batch_val, y_batch_val))\r\n",
        "\r\n",
        "    val_ssim = tf.reduce_mean(val_ssim_batch_acc)\r\n",
        "    print(\"Validation acc: %.4f\" % (float(val_ssim),))\r\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\r\n",
        "\r\n",
        "generator.save('gen_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-edd0e0373124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStart of epoch %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EPOCHS' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVF1A8PwIzCN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cShirfMlBA91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}